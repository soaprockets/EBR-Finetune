{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EBR Fine-tuning, Inference, and Embedding Visualization\n",
        "This notebook consolidates the existing `ebr_finetune.py`, `ebr_infer.py`, and `ebr_dim_reduction_vis.py` scripts into a single, parameterized workflow. Adjust the configuration cells as needed, then execute the desired sections (fine-tuning, batch inference, visualization) end-to-end.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How to Use\n",
        "1. Review the dependency versions in `requirements.txt` and install them in the current environment.\n",
        "2. Update the configuration dictionaries (paths, batch sizes, prompt text, etc.) to match your data layout.\n",
        "3. Enable the `RUN_*` flags before executing the fine-tuning, inference, or visualization cells.\n",
        "4. Optional: skip costly steps (e.g., training) by leaving the corresponding flag set to `False`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import logging\n",
        "import random\n",
        "from dataclasses import dataclass, asdict\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, List, Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import umap\n",
        "import dask.dataframe as dd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import (\n",
        "    silhouette_score,\n",
        "    calinski_harabasz_score,\n",
        "    davies_bouldin_score,\n",
        ")\n",
        "\n",
        "from datasets import load_dataset\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sentence_transformers.evaluation import TripletEvaluator, SimilarityFunction\n",
        "from sentence_transformers.losses import MultipleNegativesSymmetricRankingLoss\n",
        "from sentence_transformers.training_args import BatchSamplers, SentenceTransformerTrainingArguments\n",
        "from sentence_transformers.trainer import SentenceTransformerTrainer\n",
        "from peft import LoraConfig, TaskType\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_negative(dataset_dict: Dict[str, List[str]]) -> List[str]:\n",
        "    candidate_pool = list(set(dataset_dict.get(\"positive\", [])))\n",
        "    negatives: List[str] = []\n",
        "    if not candidate_pool:\n",
        "        return negatives\n",
        "    for pos in dataset_dict.get(\"positive\", []):\n",
        "        neg = random.choice(candidate_pool)\n",
        "        while neg == pos and len(candidate_pool) > 1:\n",
        "            neg = random.choice(candidate_pool)\n",
        "        negatives.append(neg)\n",
        "    return negatives\n",
        "\n",
        "\n",
        "def add_prompt_to_text(text: str, prompt: str) -> str:\n",
        "    if isinstance(text, str) and text.strip():\n",
        "        return f\"{prompt} {text}\"\n",
        "    return text\n",
        "\n",
        "\n",
        "def add_prompt_to_example(example: Dict[str, Any], prompt: str) -> Dict[str, Any]:\n",
        "    for key, value in example.items():\n",
        "        if isinstance(value, list):\n",
        "            example[key] = [add_prompt_to_text(v, prompt) for v in value]\n",
        "        elif isinstance(value, str):\n",
        "            example[key] = add_prompt_to_text(value, prompt)\n",
        "    return example\n",
        "\n",
        "\n",
        "def print_trainable_parameters(model: SentenceTransformer) -> None:\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    pct = 100 * trainable_params / total_params if total_params else 0\n",
        "    print(\n",
        "        f\"Trainable params: {trainable_params} | All params: {total_params} | Trainable %: {pct:.2f}\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class FinetuneConfig:\n",
        "    model_name: str = \"./model/KaLM-embedding-multilingual-mini-instruct-v2.5\"\n",
        "    trust_remote_code: bool = True\n",
        "    lora_r: int = 64\n",
        "    lora_alpha: int = 128\n",
        "    lora_dropout: float = 0.1\n",
        "    data_path: str = \"./train_text\"\n",
        "    use_prompt: bool = True\n",
        "    prompt: str = \"Instruct: Retrieve semantically similar text.\\nQuery:\"\n",
        "    test_size: float = 0.2\n",
        "    seed: int = 12\n",
        "    output_dir: str = \"./saved_model\"\n",
        "    num_epochs: int = 1\n",
        "    train_batch_size: int = 6\n",
        "    eval_batch_size: int = 4\n",
        "    learning_rate: float = 2e-4\n",
        "    weight_decay: float = 0.01\n",
        "    eval_steps: int = 500\n",
        "    save_steps: int = 500\n",
        "    warmup_steps: int = 300\n",
        "    logging_steps: int = 100\n",
        "    fp16: bool = True\n",
        "    bf16: bool = False\n",
        "    max_seq_length: int = 256\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class InferenceConfig:\n",
        "    model_path: str = \"./saved_model/KaLM-embedding-multilingual-mini-instruct-v2.5-peft-lora/checkpoint-500\"\n",
        "    truncate_dim: Optional[int] = 256\n",
        "    infer_data_dir: str = \"./infer_data\"\n",
        "    batch_size: int = 512\n",
        "    description_column: str = \"description\"\n",
        "    csv_sep: str = \"\\001\"\n",
        "    read_csv_kwargs: Optional[Dict[str, Any]] = None\n",
        "    prompt: str = \"Instruct: Retrieve semantically similar text.\\nQuery:\"\n",
        "    output_path: str = \"./faiss/embeds_2.txt\"\n",
        "    vector_column: str = \"vector\"\n",
        "    output_columns: Optional[List[str]] = None\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class VisualizationConfig:\n",
        "    embeddings_path: str = \"./faiss/embeds_2.txt\"\n",
        "    csv_sep: str = \"\\001\"\n",
        "    vector_column: str = \"vector\"\n",
        "    label_column: str = \"label\"\n",
        "    chunk_size: Optional[int] = None\n",
        "    chinese_fonts: Optional[List[str]] = None\n",
        "    tsne_perplexity: int = 30\n",
        "    tsne_learning_rate: int = 200\n",
        "    umap_neighbors: int = 15\n",
        "    random_state: int = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_sentence_transformer(cfg: FinetuneConfig) -> str:\n",
        "    logging.basicConfig(\n",
        "        format=\"%(asctime)s - %(message)s\",\n",
        "        datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
        "        level=logging.INFO,\n",
        "    )\n",
        "    base_model = SentenceTransformer(cfg.model_name)\n",
        "    lora_config = LoraConfig(\n",
        "        task_type=TaskType.FEATURE_EXTRACTION,\n",
        "        r=cfg.lora_r,\n",
        "        lora_alpha=cfg.lora_alpha,\n",
        "        lora_dropout=cfg.lora_dropout,\n",
        "        bias=\"none\",\n",
        "        target_modules=[\n",
        "            \"q_proj\",\n",
        "            \"k_proj\",\n",
        "            \"v_proj\",\n",
        "            \"o_proj\",\n",
        "            \"down_proj\",\n",
        "            \"gate_proj\",\n",
        "            \"up_proj\",\n",
        "        ],\n",
        "    )\n",
        "    base_model.add_adapter(lora_config)\n",
        "    print_trainable_parameters(base_model)\n",
        "\n",
        "    data_dir = Path(cfg.data_path)\n",
        "    json_files = [str(p) for p in data_dir.glob(\"*.json\")]\n",
        "    if not json_files:\n",
        "        raise FileNotFoundError(f\"No json files found under {data_dir}\")\n",
        "\n",
        "    dataset = load_dataset(\"json\", data_files=json_files)\n",
        "    dataset = dataset.filter(lambda example: example != \"\")\n",
        "\n",
        "    if cfg.use_prompt:\n",
        "        dataset = dataset.map(lambda x: add_prompt_to_example(x, cfg.prompt))\n",
        "\n",
        "    dataset_dict = dataset[\"train\"].train_test_split(\n",
        "        test_size=cfg.test_size, seed=cfg.seed\n",
        "    )\n",
        "    train_dataset = dataset_dict[\"train\"]\n",
        "    eval_dataset = dataset_dict[\"test\"]\n",
        "\n",
        "    loss = MultipleNegativesSymmetricRankingLoss(base_model)\n",
        "    run_name = f\"{Path(cfg.model_name).name}-peft-lora\"\n",
        "    output_dir = Path(cfg.output_dir) / run_name\n",
        "\n",
        "    training_args = SentenceTransformerTrainingArguments(\n",
        "        output_dir=str(output_dir),\n",
        "        num_train_epochs=cfg.num_epochs,\n",
        "        per_device_train_batch_size=cfg.train_batch_size,\n",
        "        per_device_eval_batch_size=cfg.eval_batch_size,\n",
        "        learning_rate=cfg.learning_rate,\n",
        "        weight_decay=cfg.weight_decay,\n",
        "        batch_sampler=BatchSamplers.NO_DUPLICATES,\n",
        "        eval_strategy=\"steps\",\n",
        "        eval_steps=cfg.eval_steps,\n",
        "        save_strategy=\"steps\",\n",
        "        save_steps=cfg.save_steps,\n",
        "        save_total_limit=3,\n",
        "        warmup_steps=cfg.warmup_steps,\n",
        "        logging_steps=cfg.logging_steps,\n",
        "        logging_dir=str(output_dir),\n",
        "        fp16=cfg.fp16,\n",
        "        bf16=cfg.bf16,\n",
        "    )\n",
        "\n",
        "    evaluator = TripletEvaluator(\n",
        "        anchors=eval_dataset[\"anchor\"],\n",
        "        positives=eval_dataset[\"positive\"],\n",
        "        negatives=generate_negative(eval_dataset),\n",
        "        main_similarity_function=SimilarityFunction.COSINE,\n",
        "        name=\"sts-dev\",\n",
        "    )\n",
        "\n",
        "    trainer = SentenceTransformerTrainer(\n",
        "        model=base_model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=eval_dataset,\n",
        "        loss=loss,\n",
        "        evaluator=[evaluator],\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    base_model.save_pretrained(str(output_dir))\n",
        "    return str(output_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_batch_inference(cfg: InferenceConfig) -> Path:\n",
        "    files = sorted(Path(cfg.infer_data_dir).glob(\"*.csv\"))\n",
        "    if not files:\n",
        "        raise FileNotFoundError(f\"No csv files found under {cfg.infer_data_dir}\")\n",
        "\n",
        "    frames = []\n",
        "    for file_path in files:\n",
        "        kwargs = cfg.read_csv_kwargs or {}\n",
        "        frame = pd.read_csv(file_path, sep=cfg.csv_sep, **kwargs)\n",
        "        frames.append(frame)\n",
        "    data = pd.concat(frames, ignore_index=True)\n",
        "    data = data.drop_duplicates()\n",
        "\n",
        "    if cfg.description_column not in data.columns:\n",
        "        raise ValueError(f\"Column '{cfg.description_column}' not found in data\")\n",
        "\n",
        "    model = SentenceTransformer(cfg.model_path, truncate_dim=cfg.truncate_dim)\n",
        "    output_path = Path(cfg.output_path)\n",
        "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    with output_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "        for start_idx in range(0, len(data), cfg.batch_size):\n",
        "            end_idx = min(start_idx + cfg.batch_size, len(data))\n",
        "            batch = data.iloc[start_idx:end_idx]\n",
        "            texts = batch[cfg.description_column].astype(str).tolist()\n",
        "            embeds = model.encode(\n",
        "                texts,\n",
        "                normalize_embeddings=True,\n",
        "                batch_size=cfg.batch_size,\n",
        "                show_progress_bar=True,\n",
        "                prompt=cfg.prompt,\n",
        "            )\n",
        "            embed_text = [\" \".join(str(x) for x in row) for row in embeds]\n",
        "            result = pd.DataFrame({cfg.vector_column: embed_text})\n",
        "            if cfg.output_columns:\n",
        "                merged = pd.concat([batch.reset_index(drop=True), result], axis=1)\n",
        "                merged = merged[cfg.output_columns]\n",
        "            else:\n",
        "                merged = pd.concat([batch.reset_index(drop=True), result], axis=1)\n",
        "            merged.to_csv(f, index=False, header=False, sep=cfg.csv_sep, mode=\"a\")\n",
        "    return output_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _configure_fonts(font_candidates: Optional[List[str]]) -> None:\n",
        "    import matplotlib.font_manager as font_manager\n",
        "\n",
        "    if not font_candidates:\n",
        "        font_candidates = [\n",
        "            \"SimHei\",\n",
        "            \"Microsoft YaHei\",\n",
        "            \"WenQuanYi Micro Hei\",\n",
        "            \"Arial Unicode MS\",\n",
        "            \"STHeiti\",\n",
        "            \"STSong\",\n",
        "        ]\n",
        "    available_fonts = {f.name for f in font_manager.fontManager.ttflist}\n",
        "    for font in font_candidates:\n",
        "        if font in available_fonts:\n",
        "            plt.rcParams[\"font.sans-serif\"] = [font]\n",
        "            break\n",
        "    plt.rcParams[\"axes.unicode_minus\"] = False\n",
        "\n",
        "\n",
        "def _compute_cluster_metrics(x: np.ndarray, labels: np.ndarray) -> Dict[str, float]:\n",
        "    metrics = {\"silhouette\": np.nan, \"calinski_harabasz\": np.nan, \"davies_bouldin\": np.nan}\n",
        "    unique_labels = np.unique(labels)\n",
        "    if len(unique_labels) < 2 or x.shape[0] <= len(unique_labels):\n",
        "        return metrics\n",
        "    try:\n",
        "        metrics[\"silhouette\"] = silhouette_score(x, labels)\n",
        "    except ValueError:\n",
        "        pass\n",
        "    try:\n",
        "        metrics[\"calinski_harabasz\"] = calinski_harabasz_score(x, labels)\n",
        "    except ValueError:\n",
        "        pass\n",
        "    try:\n",
        "        metrics[\"davies_bouldin\"] = davies_bouldin_score(x, labels)\n",
        "    except ValueError:\n",
        "        pass\n",
        "    return metrics\n",
        "\n",
        "\n",
        "def _format_metrics_text(name: str, metrics: Dict[str, float]) -> str:\n",
        "    def fmt(value: float) -> str:\n",
        "        return \"nan\" if np.isnan(value) else f\"{value:.3f}\"\n",
        "\n",
        "    return (\n",
        "        f\"{name}\\n\"\n",
        "        f\"Silhouette: {fmt(metrics['silhouette'])}\\n\"\n",
        "        f\"C-H: {fmt(metrics['calinski_harabasz'])}\\n\"\n",
        "        f\"D-B: {fmt(metrics['davies_bouldin'])}\"\n",
        "    )\n",
        "\n",
        "\n",
        "def visualize_embeddings(cfg: VisualizationConfig, save_path: str = \"./embedding_scatter.png\") -> Path:\n",
        "    _configure_fonts(cfg.chinese_fonts)\n",
        "    df = dd.read_csv(\n",
        "        cfg.embeddings_path,\n",
        "        sep=cfg.csv_sep,\n",
        "        header=None,\n",
        "        names=[cfg.label_column, cfg.vector_column]\n",
        "        if cfg.label_column != cfg.vector_column\n",
        "        else None,\n",
        "        blocksize=cfg.chunk_size,\n",
        "    ).compute()\n",
        "\n",
        "    if cfg.vector_column not in df.columns:\n",
        "        raise ValueError(f\"Column '{cfg.vector_column}' not found in file {cfg.embeddings_path}\")\n",
        "\n",
        "    df[cfg.vector_column] = df[cfg.vector_column].apply(\n",
        "        lambda x: [float(i) for i in str(x).split(\" \")]\n",
        "    )\n",
        "    embeddings = np.array(df[cfg.vector_column].tolist())\n",
        "\n",
        "    if cfg.label_column not in df.columns:\n",
        "        labels = np.zeros(len(df))\n",
        "    else:\n",
        "        labels = df[cfg.label_column].values\n",
        "\n",
        "    tsne_model = TSNE(\n",
        "        n_components=2,\n",
        "        random_state=cfg.random_state,\n",
        "        perplexity=cfg.tsne_perplexity,\n",
        "        learning_rate=cfg.tsne_learning_rate,\n",
        "    )\n",
        "    tsne_2d = tsne_model.fit_transform(embeddings)\n",
        "\n",
        "    umap_model = umap.UMAP(\n",
        "        n_components=2,\n",
        "        random_state=cfg.random_state,\n",
        "        n_neighbors=cfg.umap_neighbors,\n",
        "    )\n",
        "    umap_2d = umap_model.fit_transform(embeddings)\n",
        "\n",
        "    metrics_original = _compute_cluster_metrics(embeddings, labels)\n",
        "    metrics_tsne = _compute_cluster_metrics(tsne_2d, labels)\n",
        "    metrics_umap = _compute_cluster_metrics(umap_2d, labels)\n",
        "\n",
        "    unique_labels = np.unique(labels)\n",
        "    color_map = {label: color for label, color in zip(unique_labels, sns.color_palette(\"husl\", len(unique_labels) or 1))}\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
        "    projections = [\n",
        "        (\"t-SNE Projection\", tsne_2d, metrics_tsne),\n",
        "        (\"UMAP Projection\", umap_2d, metrics_umap),\n",
        "    ]\n",
        "\n",
        "    for ax, (title, values, metric_values) in zip(axes, projections):\n",
        "        tmp_df = pd.DataFrame(values, columns=[\"x\", \"y\"])\n",
        "        tmp_df[\"label\"] = labels\n",
        "        sns.scatterplot(\n",
        "            x=\"x\",\n",
        "            y=\"y\",\n",
        "            hue=\"label\",\n",
        "            data=tmp_df,\n",
        "            ax=ax,\n",
        "            palette=color_map,\n",
        "            alpha=0.6,\n",
        "            s=50,\n",
        "            legend=False,\n",
        "        )\n",
        "        ax.set_title(title)\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "        ax.text(\n",
        "            0.02,\n",
        "            0.98,\n",
        "            _format_metrics_text(title, metric_values),\n",
        "            transform=ax.transAxes,\n",
        "            ha=\"left\",\n",
        "            va=\"top\",\n",
        "            bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", alpha=0.7),\n",
        "        )\n",
        "\n",
        "    fig.text(\n",
        "        0.5,\n",
        "        0.02,\n",
        "        _format_metrics_text(\"Original Embeddings\", metrics_original),\n",
        "        ha=\"center\",\n",
        "        va=\"bottom\",\n",
        "        fontsize=12,\n",
        "        bbox=dict(boxstyle=\"round,pad=0.4\", fc=\"white\", alpha=0.8),\n",
        "    )\n",
        "    fig.text(\n",
        "        0.5,\n",
        "        0.95,\n",
        "        \"指标解读：Silhouette/CH 越大越好，Davies-Bouldin 越小越好\",\n",
        "        ha=\"center\",\n",
        "        va=\"top\",\n",
        "        fontsize=12,\n",
        "        color=\"dimgray\",\n",
        "    )\n",
        "\n",
        "    save_path = Path(save_path)\n",
        "    save_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    fig.savefig(save_path, dpi=180, bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "    return save_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "FINETUNE_CONFIG = FinetuneConfig(\n",
        "    model_name=\"./model/KaLM-embedding-multilingual-mini-instruct-v2.5\",\n",
        "    data_path=\"./train_text\",\n",
        "    output_dir=\"./saved_model\",\n",
        ")\n",
        "\n",
        "INFERENCE_CONFIG = InferenceConfig(\n",
        "    model_path=\"./saved_model/KaLM-embedding-multilingual-mini-instruct-v2.5-peft-lora/checkpoint-500\",\n",
        "    infer_data_dir=\"./infer_data\",\n",
        "    description_column=\"description\",\n",
        "    read_csv_kwargs={\"names\": [\"description\"], \"engine\": \"python\"},\n",
        "    output_columns=[\"description\", \"vector\"],\n",
        ")\n",
        "\n",
        "VIS_CONFIG = VisualizationConfig(\n",
        "    embeddings_path=\"./faiss/embeds_2.txt\",\n",
        "    label_column=\"label\",\n",
        "    vector_column=\"vector\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "RUN_FINETUNE = False\n",
        "RUN_INFERENCE = False\n",
        "RUN_VISUALIZATION = False\n",
        "\n",
        "trained_model_path = INFERENCE_CONFIG.model_path\n",
        "\n",
        "if RUN_FINETUNE:\n",
        "    trained_model_path = train_sentence_transformer(FINETUNE_CONFIG)\n",
        "    INFERENCE_CONFIG.model_path = trained_model_path\n",
        "    print(f\"Model saved to {trained_model_path}\")\n",
        "\n",
        "if RUN_INFERENCE:\n",
        "    output_file = run_batch_inference(INFERENCE_CONFIG)\n",
        "    print(f\"Embeddings written to {output_file}\")\n",
        "\n",
        "if RUN_VISUALIZATION:\n",
        "    vis_path = visualize_embeddings(VIS_CONFIG)\n",
        "    print(f\"Visualization saved to {vis_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "Need to customize something else? Document questions directly inside the corresponding config cell so future runs stay reproducible. Happy fine-tuning!\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
